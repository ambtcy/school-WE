{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f01c187-6b2b-4fd1-9436-6ea92556b84f",
   "metadata": {},
   "source": [
    "# HSST B10m Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea2730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
    "from sklearn.model_selection import cross_val_score, train_test_split,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6765b75-c14c-4701-94b8-97711c2864c6",
   "metadata": {},
   "source": [
    "### Data generator\n",
    "Experiment with changing noise, test/train split and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a8d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate spiral data (see https://gist.github.com/45deg/e731d9e7f478de134def5668324c44c5)\n",
    "noise = 1.0\n",
    "N = 200\n",
    "split = 0.25\n",
    "\n",
    "theta = np.sqrt(np.random.rand(N))*2*pi # np.linspace(0,2*pi,100)\n",
    "\n",
    "r_a = 2*theta + pi\n",
    "data_a = np.array([np.cos(theta)*r_a, np.sin(theta)*r_a]).T\n",
    "x_a = data_a + noise*np.random.randn(N,2)\n",
    "\n",
    "r_b = -2*theta - pi\n",
    "data_b = np.array([np.cos(theta)*r_b, np.sin(theta)*r_b]).T\n",
    "x_b = data_b + noise*np.random.randn(N,2)\n",
    "\n",
    "res_a = np.append(x_a, np.zeros((N,1)), axis=1)\n",
    "res_b = np.append(x_b, np.ones((N,1)), axis=1)\n",
    "\n",
    "res = np.append(res_a, res_b, axis=0)\n",
    "np.random.shuffle(res)\n",
    "\n",
    "plt.scatter(x_a[:,0],x_a[:,1])\n",
    "plt.scatter(x_b[:,0],x_b[:,1])\n",
    "X=np.r_[x_a,x_b]\n",
    "y=np.r_[np.zeros(N),np.ones(N)]\n",
    "print(\"Input data\")\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=split, random_state=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d90d06-1940-4f07-882c-660936411ec0",
   "metadata": {},
   "source": [
    "## Basic Decision Tree\n",
    "Experiment with changing the maximum depth of the tree, how does this effect the AUC.\n",
    "Does the average AUC predicted by cross validation agree with the value from the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908ab828-053b-4411-a0ab-218decbec679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_depth = None # how deep the tree generated can go, None is uncapped, experiment with lower values\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0,max_depth=max_depth)\n",
    "\n",
    "print(\"10 fold cross validation\")\n",
    "print(cross_val_score(clf, X_train,y_train, scoring='roc_auc', cv=10))\n",
    "\n",
    "print(\"Final model\")\n",
    "clf = clf.fit(X_train,y_train)\n",
    "print(\"AUC\",roc_auc_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "clf_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
    "plt.show()\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c0134-ea1b-40a1-93de-ce260b0a84ae",
   "metadata": {},
   "source": [
    "### Decision boundary plot\n",
    "This is a helper that shows the decision boundaries for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e4ced8-83cd-43aa-844a-26515c198984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundaries(_X, _y, tree):\n",
    "    feature_1, feature_2 = np.meshgrid(\n",
    "        np.linspace(_X[:, 0].min(), _X[:, 0].max()),\n",
    "        np.linspace(_X[:, 1].min(), _X[:, 1].max())\n",
    "    )\n",
    "    grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
    "    y_pred = np.reshape(tree.predict(grid), feature_1.shape)\n",
    "    display = DecisionBoundaryDisplay(\n",
    "        xx0=feature_1, xx1=feature_2, response=y_pred\n",
    "    )\n",
    "    display.plot(alpha=0.5, cmap=\"plasma\")\n",
    "    display.ax_.scatter(\n",
    "        _X[:, 0], _X[:, 1], c=_y, edgecolor=\"black\"\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Decision Boundary Plot\")\n",
    "print(\"Training data\")\n",
    "plot_decision_boundaries(X_train, y_train, clf)\n",
    "print(\"Test data\")\n",
    "plot_decision_boundaries(X_test, y_test, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cba07a-8331-4ddc-8ad1-5ad44ab26819",
   "metadata": {},
   "source": [
    "## Bagging - Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c7b3e-43c0-406c-a82c-caed71e1d250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameter dictionary\n",
    "param_dist={\n",
    "    'n_estimators':range(50,100), # size of forest\n",
    "    'max_depth':range(1,20) # depth of forest - \"pruning\"\n",
    "}\n",
    "\n",
    "# perform a \"randomised\" grid search of hyperparameters\n",
    "print(\"Picking hyperparameters\")\n",
    "rf = RandomForestClassifier()\n",
    "rand_search=RandomizedSearchCV(rf,\n",
    "                               param_distributions=param_dist,\n",
    "                               n_iter=5, \n",
    "                               cv=5)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "# get best model and parameters\n",
    "best_rf = rand_search.best_estimator_\n",
    "print(rand_search.best_params_)\n",
    "\n",
    "# evaluate best model\n",
    "print(\"AUC\", roc_auc_score(y_test, best_rf.predict(X_test)))\n",
    "\n",
    "# print decision boundary plot.\n",
    "print(\"Decision Boundary Plot\")\n",
    "print(\"Training data\")\n",
    "plot_decision_boundaries(X_train, y_train, best_rf)\n",
    "print(\"Test data\")\n",
    "plot_decision_boundaries(X_test, y_test, best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b956a11-d927-4954-9dbe-178ece88fe66",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e3233-95c6-4715-a3a6-cc15c08738dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_depth = 4\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(random_state=0,max_depth=max_depth), n_estimators=300, random_state=0\n",
    ")\n",
    "\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"AUC\", roc_auc_score(y_test, ada_clf.predict(X_test)))\n",
    "\n",
    "# print decision boundary plot.\n",
    "print(\"Decision Boundary Plot\")\n",
    "print(\"Training data\")\n",
    "plot_decision_boundaries(X_train, y_train, ada_clf)\n",
    "print(\"Test data\")\n",
    "plot_decision_boundaries(X_test, y_test, ada_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (2023)",
   "language": "python",
   "name": "python3-2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
